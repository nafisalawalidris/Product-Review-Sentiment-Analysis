{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Product Review Sentiment Analysis and Rating Prediction** #\n",
    "\n",
    "This project aims to analyse customer product reviews and predict the sentiment associated with the review text, leveraging Natural Language Processing (NLP) techniques and machine learning models. Sentiment analysis is key for understanding customer feedback and improving product quality, services and user satisfaction. The goal is to identify patterns in the reviews and classify them as positive, neutral or negative while exploring the correlation between review text and ratings.\n",
    "\n",
    "**Problem Statement**: Given a dataset of product reviews with corresponding ratings, the challenge is to build a machine learning model that can predict the rating based on the review text. This can help companies automatically assess customer satisfaction and make data-driven decisions to improve their products and services. We will explore several models and assess their performance in terms of accuracy, precision and recall.\n",
    "\n",
    "### **Key Steps in the Project** ###\n",
    "- Data Collection: Load the dataset containing product reviews and ratings.\n",
    "- Data Preparation: Clean and preprocess the data to ensure it is suitable for analysis.\n",
    "- Exploratory Data Analysis (EDA): Understand the data structure, distribution of ratings and word frequencies in the reviews.\n",
    "- Text Preprocessing: Tokenisation, removing stopwords, stemming/lemmatisation and vectorisation.\n",
    "- Sentiment Analysis: Use NLP techniques to classify reviews into positive, neutral or negative sentiments.\n",
    "- Model Selection: Train different machine learning models to predict product ratings.\n",
    "- Evaluation: Compare model performance using relevant metrics like accuracy, precision and recall.\n",
    "- Visualisation: Use visual tools to showcase key findings, such as the distribution of sentiment and model predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Load the Dataset** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset, specifying the correct delimiter (comma in this case)\n",
    "data = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\Sentiment Analysis for Product Reviews\\Amazon Product Review.txt\", delimiter=',')\n",
    "\n",
    "# Display the actual column names in the dataset\n",
    "print(\"Columns in the dataset:\")\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Inspect the Dataset for Missing or Inconsistent Values** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "marketplace          0\n",
      "customer_id          0\n",
      "review_id            0\n",
      "product_id           0\n",
      "product_parent       0\n",
      "product_title        0\n",
      "product_category     0\n",
      "star_rating          0\n",
      "helpful_votes        0\n",
      "total_votes          0\n",
      "vine                 0\n",
      "verified_purchase    0\n",
      "review_headline      2\n",
      "review_body          4\n",
      "review_date          0\n",
      "sentiment            0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in the 'star_rating' column:\n",
      "[5 3 4 2 1]\n",
      "\n",
      "Preview of relevant columns:\n",
      "                                         review_body  star_rating\n",
      "0                                      Great love it            5\n",
      "1  Lots of ads<br />Slow processing speed<br />Oc...            3\n",
      "2  Excellent unit.  The versatility of this table...            5\n",
      "3  I bought this on Amazon Prime so I ended up bu...            4\n",
      "4  All Amazon products continue to meet my expect...            5\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Display the count of missing values for each column\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Define the relevant columns\n",
    "required_columns = ['review_body', 'star_rating']  \n",
    "\n",
    "# Check the unique values in the star_rating column to identify inconsistencies\n",
    "if 'star_rating' in data.columns:\n",
    "    unique_ratings = data['star_rating'].unique()\n",
    "    print(\"\\nUnique values in the 'star_rating' column:\")\n",
    "    print(unique_ratings)\n",
    "\n",
    "# Display the first few rows of the relevant columns for verification\n",
    "print(\"\\nPreview of relevant columns:\")\n",
    "print(data[required_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Data Cleaning** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of cleaned review body:\n",
      "                                 cleaned_review_body  star_rating\n",
      "0                                      great love it            5\n",
      "1  lots of adsslow processing speedoccasionally s...            3\n",
      "2  excellent unit  the versatility of this tablet...            5\n",
      "3  i bought this on amazon prime so i ended up bu...            4\n",
      "4  all amazon products continue to meet my expect...            5\n"
     ]
    }
   ],
   "source": [
    "# 1. Handle Missing Values\n",
    "data.dropna(subset=['review_body'], inplace=True)  # Drop rows with missing review_body\n",
    "\n",
    "# 2. Text Preprocessing\n",
    "import re\n",
    "\n",
    "# Function to clean the review text\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags (if needed)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the review_body\n",
    "data['cleaned_review_body'] = data['review_body'].apply(clean_text)\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "print(\"\\nPreview of cleaned review body:\")\n",
    "print(data[['cleaned_review_body', 'star_rating']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Sentiment Analysis Preparation** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (24673, 5000)\n",
      "Testing data shape: (6169, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Feature Extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for simplicity\n",
    "X = vectorizer.fit_transform(data['cleaned_review_body'])\n",
    "\n",
    "# 2. Prepare target variable\n",
    "y = data['star_rating']\n",
    "\n",
    "# 3. Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Train a Model** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54       327\n",
      "           2       0.35      0.08      0.13       219\n",
      "           3       0.36      0.25      0.29       410\n",
      "           4       0.51      0.34      0.41      1193\n",
      "           5       0.80      0.95      0.87      4020\n",
      "\n",
      "    accuracy                           0.73      6169\n",
      "   macro avg       0.51      0.43      0.45      6169\n",
      "weighted avg       0.69      0.73      0.70      6169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Product_Review_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
